{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imageio: 'ffmpeg.linux64' was not found on your computer; downloading it now.\n",
      "Error while fetching file: The read operation timed out.\n",
      "Try 2. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg.linux64 (27.2 MB)\n",
      "Downloading: 8192/28549024 bytes (0.016384/28549024 bytes (0.1%40960/28549024 bytes (0.1%90112/28549024 bytes (0.3%204800/28549024 bytes (0.7368640/28549024 bytes (1.3483328/28549024 bytes (1.7663552/28549024 bytes (2.3794624/28549024 bytes (2.8958464/28549024 bytes (3.41138688/28549024 bytes (4.0%1302528/28549024 bytes (4.6%1499136/28549024 bytes (5.3%1728512/28549024 bytes (6.1%1941504/28549024 bytes (6.8%2187264/28549024 bytes (7.7%2498560/28549024 bytes (8.8%2744320/28549024 bytes (9.6%3022848/28549024 bytes (10.63334144/28549024 bytes (11.73694592/28549024 bytes (12.93989504/28549024 bytes (14.04333568/28549024 bytes (15.24710400/28549024 bytes (16.55185536/28549024 bytes (18.25627904/28549024 bytes (19.76053888/28549024 bytes (21.26479872/28549024 bytes (22.76922240/28549024 bytes (24.27413760/28549024 bytes (26.07856128/28549024 bytes (27.58282112/28549024 bytes (29.08757248/28549024 bytes (30.79281536/28549024 bytes (32.59674752/28549024 bytes (33.910100736/28549024 bytes (35.4%10543104/28549024 bytes (36.9%11051008/28549024 bytes (38.7%11591680/28549024 bytes (40.6%12132352/28549024 bytes (42.5%12738560/28549024 bytes (44.6%13418496/28549024 bytes (47.0%14114816/28549024 bytes (49.4%14753792/28549024 bytes (51.7%15507456/28549024 bytes (54.3%16113664/28549024 bytes (56.4%16277504/28549024 bytes (57.0%16687104/28549024 bytes (58.5%18145280/28549024 bytes (63.6%18587648/28549024 bytes (65.1%18923520/28549024 bytes (66.3%19292160/28549024 bytes (67.6%19652608/28549024 bytes (68.8%20013056/28549024 bytes (70.1%20324352/28549024 bytes (71.2%20733952/28549024 bytes (72.6%21159936/28549024 bytes (74.1%21594112/28549024 bytes (75.6%22077440/28549024 bytes (77.3%22552576/28549024 bytes (79.0%22945792/28549024 bytes (80.4%23355392/28549024 bytes (81.8%23830528/28549024 bytes (83.5%24256512/28549024 bytes (85.0%24666112/28549024 bytes (86.4%25092096/28549024 bytes (87.9%25534464/28549024 bytes (89.4%25960448/28549024 bytes (90.9%26419200/28549024 bytes (92.5%26861568/28549024 bytes (94.1%27336704/28549024 bytes (95.8%27795456/28549024 bytes (97.4%28270592/28549024 bytes (99.0%28549024/28549024 bytes (100.0%)\n",
      "  Done\n",
      "File saved as /root/.imageio/ffmpeg/ffmpeg.linux64.\n"
     ]
    }
   ],
   "source": [
    "import numpy as nm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def colorSelect(image):\n",
    "    white_th  = [200,200,200]\n",
    "    orange_th = [230, 130, 10]\n",
    "    \n",
    "    color_select = nm.copy(image)\n",
    "    rgb_threshold = (image[:,:,0] < white_th[0]) | (image[:,:,1] < white_th[1]) | (image[:,:,2] < white_th[2]) \n",
    "\n",
    "    orange_threshold = (image[:,:,0] < orange_th[0]) | (image[:,:,1] < orange_th[1]) | (image[:,:,2] < orange_th[2])\n",
    "    \n",
    "    color_select[rgb_threshold&orange_threshold] = [0,0,0]  \n",
    "    \n",
    "    return color_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def regionMask(image):\n",
    "    region_select = nm.copy(image)\n",
    "    \n",
    "    left_bottom = [0,image.shape[0]]\n",
    "    right_bottom = [image.shape[1], image.shape[0]]\n",
    "    apex = [image.shape[1]/2, image.shape[0]/2]\n",
    "    \n",
    "    xsize = image.shape[1]\n",
    "    ysize = image.shape[0]\n",
    "    \n",
    "    \n",
    "    # Perform a linear fit (y=Ax+B) to each of the three sides of the triangle\n",
    "    # np.polyfit returns the coefficients [A, B] of the fit\n",
    "    fit_left = nm.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "    fit_right = nm.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "    fit_bottom = nm.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "\n",
    "    # Find the region inside the lines\n",
    "    XX, YY = nm.meshgrid(nm.arange(0, xsize), nm.arange(0, ysize))\n",
    "    region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                        (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                        (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "\n",
    "    region_select[~region_thresholds] = [0,0,0] \n",
    "   # region_select[region_thresholds] = [255,255,255] \n",
    "    \n",
    "    return region_select "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cannyFilter(image):\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Define a kernel size for Gaussian smoothing / blurring\n",
    "    kernel_size = 3 # Must be an odd number (3, 5, 7...)\n",
    "    blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "\n",
    "    # Define our parameters for Canny and run it\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "        \n",
    "    return edges\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hough(image):\n",
    "    # Define the Hough transform parameters\n",
    "    # Make a blank the same size as our image to draw on\n",
    "    rho = 2 # distance resolution in pixels of the Hough grid\n",
    "    theta = nm.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 15     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 40 #minimum number of pixels making up a line\n",
    "    max_line_gap = 20    # maximum gap in pixels between connectable line segments\n",
    "    \n",
    "    #img_gs = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    line_image = nm.copy(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))*0 # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(image, rho, theta, threshold, nm.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "    if lines is None:\n",
    "            return line_image\n",
    "    \n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "    \n",
    "    \n",
    "    return line_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detectLine(image):\n",
    "    i = nm.copy(image)\n",
    "    region_img = regionMask(image)\n",
    "    color_img = colorSelect(region_img)\n",
    "    canny_img = cannyFilter(color_img)\n",
    "    lines =  hough(canny_img)\n",
    "    \n",
    "    result = cv2.addWeighted(lines, 0.8, image, 1, 0) \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f56882c3940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = cv2.imread('./test.jpg')\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5664b474a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./test.jpg')\n",
    "\n",
    "img = colorSelect(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f56882d1630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./test.jpg')\n",
    "img = regionMask(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f56882d1e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./test.jpg')\n",
    "img = cannyFilter(img)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_GRAY2RGB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5664b44c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread('./test.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "hough_img = detectLine(img)\n",
    "\n",
    "plt.imshow(hough_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "    <source src=\"test.mp4\" type=\"video/mp4\">\n",
       "</video>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"test.mp4\" type=\"video/mp4\">\n",
    "</video>    \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_output.mp4\n",
      "[MoviePy] Writing video test_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:20<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_output.mp4 \n",
      "\n",
      "CPU times: user 26.4 s, sys: 2.62 s, total: 29.1 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_clip_output = 'test_output.mp4'\n",
    "test_clip = VideoFileClip(\"test.mp4\")\n",
    "new_clip = test_clip.fl_image(lambda x: detectLine(x))\n",
    "#new_clip = test_clip.fl_image(lambda x: x)\n",
    "\n",
    "%time new_clip.write_videofile(new_clip_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "    <source src=\"test_output.mp4\" type=\"video/mp4\">}\n",
       "</video>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"test_output.mp4\" type=\"video/mp4\">}\n",
    "</video>    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
